{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc63030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading class mapping from: class_mapping.json\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_24848\\3271592363.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting image: dataset\\images\\test\\Hummus\\65570.jpg\n",
      "-> Predicted Class: Cucumber\n",
      "-> Confidence: 0.3880\n"
     ]
    }
   ],
   "source": [
    "### Inference on a single image\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import EfficientNet_V2_S_Weights, efficientnet_v2_s\n",
    "from PIL import Image\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_PATH = 'models/efficientnetv2s/best_model.pth'\n",
    "# IMAGE_PATH = r'dataset\\images\\test\\Hummus\\18.jpg'  # <<<--- Change this to your image file\n",
    "IMAGE_PATH = r\"dataset\\images\\test\\Hummus\\65570.jpg\"\n",
    "MAPPING_JSON_PATH = 'class_mapping.json'\n",
    "NUM_CLASSES = 64\n",
    "\n",
    "# --- Device Setup ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Load Class Mapping ---\n",
    "print(f\"Loading class mapping from: {MAPPING_JSON_PATH}\")\n",
    "try:\n",
    "    with open(MAPPING_JSON_PATH, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    if len(idx_to_class) != NUM_CLASSES:\n",
    "        print(f\"Warning: Found {len(idx_to_class)} classes, expected {NUM_CLASSES}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load class mapping: {e}\")\n",
    "\n",
    "# --- Load Model ---\n",
    "print(\"Loading model...\")\n",
    "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "model = efficientnet_v2_s(weights=weights)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Dropout(p=0.37, inplace=True), # Keep dropout\n",
    "    nn.Linear(num_ftrs, NUM_CLASSES),\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# --- Prediction Function ---\n",
    "def predict_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            conf, idx = torch.max(torch.softmax(output, dim=1), 1)\n",
    "        return idx_to_class.get(idx.item(), \"Unknown\"), conf.item()\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- Inference ---\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    print(f\"Image path does not exist: {IMAGE_PATH}\")\n",
    "else:\n",
    "    print(f\"Predicting image: {IMAGE_PATH}\")\n",
    "    label, confidence = predict_image(IMAGE_PATH)\n",
    "    if label:\n",
    "        print(f\"-> Predicted Class: {label}\")\n",
    "        print(f\"-> Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9fde5",
   "metadata": {},
   "source": [
    "#### Yolov8 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9398abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 image(s) to process.\n",
      "\n",
      "Processing: dataset/images/test/Dates_with_tahini\\test_69.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Dates_with_tahini\\test_69.jpg: 640x448 2 Foods, 77.3ms\n",
      "Speed: 3.0ms preprocess, 77.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_test_69.jpg\n",
      "\n",
      "Processing: dataset/images/test/Dates_with_tahini\\train_61.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Dates_with_tahini\\train_61.jpg: 448x640 1 Baked goods, 7 Cookies, 2 Desserts, 25.5ms\n",
      "Speed: 2.5ms preprocess, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Saved annotated image to: outputs/annotated_train_61.jpg\n",
      "\n",
      "Processing: dataset/images/test/Dates_with_tahini\\train_75.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Dates_with_tahini\\train_75.jpg: 640x448 3 Baked goodss, 6 Desserts, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_train_75.jpg\n",
      "\n",
      "Processing: dataset/images/test/Dates_with_tahini\\Screenshot 2025-05-14 162517.png\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Dates_with_tahini\\Screenshot 2025-05-14 162517.png: 640x640 1 Dessert, 14 Foods, 16.7ms\n",
      "Speed: 2.8ms preprocess, 16.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved annotated image to: outputs/annotated_Screenshot 2025-05-14 162517.png\n",
      "\n",
      "Processing: dataset/images/test/Dates_with_tahini\\train_10.png\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Dates_with_tahini\\train_10.png: 448x640 2 Baked goodss, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Saved annotated image to: outputs/annotated_train_10.png\n",
      "\n",
      "Processing: dataset/images/test/Dates_with_tahini\\train_68.png\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Dates_with_tahini\\train_68.png: 640x448 8 Baked goodss, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_train_68.png\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Load the YOLOv8x model pretrained on Open Images V7\n",
    "# model = YOLO(r\"models\\yolov8m-oiv7\\weights\\best.pt\")\n",
    "model = YOLO(r\"models\\yolov8m-oiv7\\train4\\weights\\best.pt\")\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"dataset/images/test/Dates_with_tahini\"\n",
    "output_dir = \"outputs/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Supported image formats\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(os.path.join(input_dir, ext)))\n",
    "\n",
    "print(f\"Found {len(image_paths)} image(s) to process.\")\n",
    "\n",
    "# Process each image\n",
    "for img_path in image_paths:\n",
    "    print(f\"\\nProcessing: {img_path}\")\n",
    "    \n",
    "    # Run prediction\n",
    "    results = model.predict(source=img_path, save=False, show=False)\n",
    "\n",
    "    for i, r in enumerate(results):\n",
    "        # print(\"\\n--- Detection Summary ---\")\n",
    "        # print(f\"Boxes: {r.boxes.xyxy}\")\n",
    "        # print(f\"Classes: {r.boxes.cls}\")\n",
    "        # print(f\"Scores: {r.boxes.conf}\")\n",
    "        # print(f\"Class names: {[r.names[int(i)] for i in r.boxes.cls]}\")\n",
    "\n",
    "        # Generate annotated image\n",
    "        annotated_image = r.plot()\n",
    "\n",
    "        # Construct output file path\n",
    "        base_name = os.path.basename(img_path)\n",
    "        output_path = os.path.join(output_dir, f\"annotated_{base_name}\")\n",
    "\n",
    "        # Save image (convert to BGR for OpenCV)\n",
    "        cv2.imwrite(output_path, annotated_image)\n",
    "        print(f\"Saved annotated image to: {output_path}\")\n",
    "\n",
    "        # Optional: Display the image\n",
    "        # plt.imshow(annotated_image)\n",
    "        # plt.axis('off')\n",
    "        # plt.title(f\"Detections for {base_name}\")\n",
    "        # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

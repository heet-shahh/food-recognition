{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc63030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading class mapping from: class_mapping.json\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_24848\\3271592363.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting image: dataset\\images\\test\\Hummus\\65570.jpg\n",
      "-> Predicted Class: Cucumber\n",
      "-> Confidence: 0.3880\n"
     ]
    }
   ],
   "source": [
    "### Inference on a single image\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import EfficientNet_V2_S_Weights, efficientnet_v2_s\n",
    "from PIL import Image\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_PATH = 'models/efficientnetv2s/best_model.pth'\n",
    "# IMAGE_PATH = r'dataset\\images\\test\\Hummus\\18.jpg'  # <<<--- Change this to your image file\n",
    "IMAGE_PATH = r\"dataset\\images\\test\\Hummus\\65570.jpg\"\n",
    "MAPPING_JSON_PATH = 'class_mapping.json'\n",
    "NUM_CLASSES = 64\n",
    "\n",
    "# --- Device Setup ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Load Class Mapping ---\n",
    "print(f\"Loading class mapping from: {MAPPING_JSON_PATH}\")\n",
    "try:\n",
    "    with open(MAPPING_JSON_PATH, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    if len(idx_to_class) != NUM_CLASSES:\n",
    "        print(f\"Warning: Found {len(idx_to_class)} classes, expected {NUM_CLASSES}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load class mapping: {e}\")\n",
    "\n",
    "# --- Load Model ---\n",
    "print(\"Loading model...\")\n",
    "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "model = efficientnet_v2_s(weights=weights)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Dropout(p=0.37, inplace=True), # Keep dropout\n",
    "    nn.Linear(num_ftrs, NUM_CLASSES),\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# --- Prediction Function ---\n",
    "def predict_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            conf, idx = torch.max(torch.softmax(output, dim=1), 1)\n",
    "        return idx_to_class.get(idx.item(), \"Unknown\"), conf.item()\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- Inference ---\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    print(f\"Image path does not exist: {IMAGE_PATH}\")\n",
    "else:\n",
    "    print(f\"Predicting image: {IMAGE_PATH}\")\n",
    "    label, confidence = predict_image(IMAGE_PATH)\n",
    "    if label:\n",
    "        print(f\"-> Predicted Class: {label}\")\n",
    "        print(f\"-> Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9fde5",
   "metadata": {},
   "source": [
    "#### Yolov8 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9398abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 image(s) to process.\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\1106758.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\1106758.jpg: 480x640 1 Food, 63.8ms\n",
      "Speed: 5.0ms preprocess, 63.8ms inference, 87.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_1106758.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\1317879.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\1317879.jpg: 640x640 1 Food, 54.0ms\n",
      "Speed: 3.4ms preprocess, 54.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved annotated image to: outputs/annotated_1317879.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\163354.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\163354.jpg: 480x640 1 Food, 37.9ms\n",
      "Speed: 1.9ms preprocess, 37.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_163354.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\169140.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\169140.jpg: 480x640 1 Food, 1 Seafood, 36.9ms\n",
      "Speed: 1.7ms preprocess, 36.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_169140.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\24646.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\24646.jpg: 640x480 1 Food, 80.8ms\n",
      "Speed: 1.6ms preprocess, 80.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved annotated image to: outputs/annotated_24646.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\256940.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\256940.jpg: 640x480 1 Baked goods, 16.8ms\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved annotated image to: outputs/annotated_256940.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\259921.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\259921.jpg: 640x480 1 Food, 17.0ms\n",
      "Speed: 1.8ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved annotated image to: outputs/annotated_259921.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\322953.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\322953.jpg: 480x640 1 Food, 2 Plates, 17.1ms\n",
      "Speed: 1.3ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_322953.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\65570.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\65570.jpg: 480x640 1 Baked goods, 2 Cucumbers, 2 Fruits, 1 Tomato, 1 Zucchini, 16.1ms\n",
      "Speed: 1.4ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_65570.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\828211.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\828211.jpg: 480x640 1 Coffee cup, 1 Food, 1 Fruit, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_828211.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\test_35.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\test_35.jpg: 640x640 1 Food, 1 Plate, 22.7ms\n",
      "Speed: 3.0ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved annotated image to: outputs/annotated_test_35.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_125.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_125.jpg: 640x448 2 Cucumbers, 1 Food, 47.1ms\n",
      "Speed: 1.7ms preprocess, 47.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_train_125.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_132.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_132.jpg: 640x512 1 Baked goods, 1 Food, 1 Salad, 1 Tomato, 44.8ms\n",
      "Speed: 1.9ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved annotated image to: outputs/annotated_train_132.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_25.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_25.jpg: 640x640 1 Coffee cup, 1 Cucumber, 2 Lemons, 22.9ms\n",
      "Speed: 3.2ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved annotated image to: outputs/annotated_train_25.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_29.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_29.jpg: 480x640 1 Baked goods, 1 Food, 16.9ms\n",
      "Speed: 1.1ms preprocess, 16.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_train_29.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_32.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_32.jpg: 640x512 1 Baked goods, 1 Food, 18.0ms\n",
      "Speed: 1.6ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved annotated image to: outputs/annotated_train_32.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_45.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_45.jpg: 640x448 11 Foods, 2 Lemons, 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_train_45.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_61.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_61.jpg: 512x640 4 Baked goodss, 2 Foods, 56.2ms\n",
      "Speed: 2.2ms preprocess, 56.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Saved annotated image to: outputs/annotated_train_61.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_68.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_68.jpg: 640x448 1 Food, 1 Lemon, 1 Salad, 1 Taco, 16.4ms\n",
      "Speed: 1.9ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_train_68.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_72.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_72.jpg: 448x640 2 Lemons, 8 Tomatos, 46.5ms\n",
      "Speed: 1.8ms preprocess, 46.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Saved annotated image to: outputs/annotated_train_72.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\train_86.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\train_86.jpg: 640x448 1 Food, 3 Lemons, 16.1ms\n",
      "Speed: 1.7ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved annotated image to: outputs/annotated_train_86.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\val_93.jpg\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\val_93.jpg: 640x480 1 Cantaloupe, 1 Cucumber, 6 Fruits, 1 Lemon, 1 Plate, 1 Tomato, 2 Zucchinis, 17.4ms\n",
      "Speed: 2.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved annotated image to: outputs/annotated_val_93.jpg\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\Screenshot 2025-05-15 143743.png\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\Screenshot 2025-05-15 143743.png: 480x640 2 Baked goodss, 2 Foods, 16.9ms\n",
      "Speed: 1.5ms preprocess, 16.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved annotated image to: outputs/annotated_Screenshot 2025-05-15 143743.png\n",
      "\n",
      "Processing: dataset/images/test/Hummus\\Screenshot 2025-05-15 144216.png\n",
      "\n",
      "image 1/1 c:\\Work\\Garbage_classification\\food-recognition\\food-recognition\\dataset\\images\\test\\Hummus\\Screenshot 2025-05-15 144216.png: 576x640 1 Taco, 63.0ms\n",
      "Speed: 2.2ms preprocess, 63.0ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Saved annotated image to: outputs/annotated_Screenshot 2025-05-15 144216.png\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Load the YOLOv8x model pretrained on Open Images V7\n",
    "model = YOLO(r\"models\\yolov8m-oiv7\\weights\\best.pt\")\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"dataset/images/test/Hummus\"\n",
    "output_dir = \"outputs/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Supported image formats\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(os.path.join(input_dir, ext)))\n",
    "\n",
    "print(f\"Found {len(image_paths)} image(s) to process.\")\n",
    "\n",
    "# Process each image\n",
    "for img_path in image_paths:\n",
    "    print(f\"\\nProcessing: {img_path}\")\n",
    "    \n",
    "    # Run prediction\n",
    "    results = model.predict(source=img_path, save=False, show=False)\n",
    "\n",
    "    for i, r in enumerate(results):\n",
    "        # print(\"\\n--- Detection Summary ---\")\n",
    "        # print(f\"Boxes: {r.boxes.xyxy}\")\n",
    "        # print(f\"Classes: {r.boxes.cls}\")\n",
    "        # print(f\"Scores: {r.boxes.conf}\")\n",
    "        # print(f\"Class names: {[r.names[int(i)] for i in r.boxes.cls]}\")\n",
    "\n",
    "        # Generate annotated image\n",
    "        annotated_image = r.plot()\n",
    "\n",
    "        # Construct output file path\n",
    "        base_name = os.path.basename(img_path)\n",
    "        output_path = os.path.join(output_dir, f\"annotated_{base_name}\")\n",
    "\n",
    "        # Save image (convert to BGR for OpenCV)\n",
    "        cv2.imwrite(output_path, annotated_image)\n",
    "        print(f\"Saved annotated image to: {output_path}\")\n",
    "\n",
    "        # Optional: Display the image\n",
    "        # plt.imshow(annotated_image)\n",
    "        # plt.axis('off')\n",
    "        # plt.title(f\"Detections for {base_name}\")\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6586b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
